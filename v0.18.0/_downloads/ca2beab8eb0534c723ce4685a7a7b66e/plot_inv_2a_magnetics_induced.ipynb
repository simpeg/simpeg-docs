{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sparse Norm Inversion for Total Magnetic Intensity Data on a Tensor Mesh\n\nHere we invert total magnetic intensity (TMI) data to recover a magnetic\nsusceptibility model. We formulate the inverse problem as an iteratively\nre-weighted least-squares (IRLS) optimization problem. For this tutorial, we\nfocus on the following:\n\n    - Defining the survey from xyz formatted data\n    - Generating a mesh based on survey geometry\n    - Including surface topography\n    - Defining the inverse problem (data misfit, regularization, optimization)\n    - Specifying directives for the inversion\n    - Setting sparse and blocky norms\n    - Plotting the recovered model and data misfit\n\nAlthough we consider TMI data in this tutorial, the same approach\ncan be used to invert other types of geophysical data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport tarfile\n\nfrom discretize import TensorMesh\n\nfrom SimPEG.potential_fields import magnetics\nfrom SimPEG.utils import plot2Ddata, surface2ind_topo, model_builder\nfrom SimPEG import (\n    maps,\n    data,\n    inverse_problem,\n    data_misfit,\n    regularization,\n    optimization,\n    directives,\n    inversion,\n    utils,\n)\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Plot\n\nFile paths for assets we are loading. To set up the inversion, we require\ntopography and field observations. The true model defined on the whole mesh\nis loaded to compare with the inversion result. These files are stored as a\ntar-file on our google cloud bucket:\n\"https://storage.googleapis.com/simpeg/doc-assets/magnetics.tar.gz\"\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# storage bucket where we have the data\ndata_source = \"https://storage.googleapis.com/simpeg/doc-assets/magnetics.tar.gz\"\n\n# download the data\ndownloaded_data = utils.download(data_source, overwrite=True)\n\n# unzip the tarfile\ntar = tarfile.open(downloaded_data, \"r\")\ntar.extractall()\ntar.close()\n\n# path to the directory containing our data\ndir_path = downloaded_data.split(\".\")[0] + os.path.sep\n\n# files to work with\ntopo_filename = dir_path + \"magnetics_topo.txt\"\ndata_filename = dir_path + \"magnetics_data.obs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Plot\n\nHere we load and plot synthetic TMI data. Topography is generally\ndefined as an (N, 3) array. TMI data is generally defined with 4 columns:\nx, y, z and data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "topo_xyz = np.loadtxt(str(topo_filename))\ndobs = np.loadtxt(str(data_filename))\n\nreceiver_locations = dobs[:, 0:3]\ndobs = dobs[:, -1]\n\n# Plot\nfig = plt.figure(figsize=(6, 5))\nv_max = np.max(np.abs(dobs))\n\nax1 = fig.add_axes([0.1, 0.1, 0.75, 0.85])\nplot2Ddata(\n    receiver_locations,\n    dobs,\n    ax=ax1,\n    ncontour=30,\n    clim=(-v_max, v_max),\n    contourOpts={\"cmap\": \"bwr\"},\n)\nax1.set_title(\"TMI Anomaly\")\nax1.set_xlabel(\"x (m)\")\nax1.set_ylabel(\"y (m)\")\n\nax2 = fig.add_axes([0.85, 0.05, 0.05, 0.9])\nnorm = mpl.colors.Normalize(vmin=-np.max(np.abs(dobs)), vmax=np.max(np.abs(dobs)))\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.bwr\n)\ncbar.set_label(\"$nT$\", rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assign Uncertainty\n\nInversion with SimPEG requires that we define standard deviation on our data.\nThis represents our estimate of the noise in our data. For magnetic inversions,\na constant floor value is generall applied to all data. For this tutorial, the\nstandard deviation on each datum will be 2% of the maximum observed magnetics\nanomaly value.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximum_anomaly = np.max(np.abs(dobs))\n\nstd = 0.02 * maximum_anomaly * np.ones(len(dobs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Survey\n\nHere, we define survey that will be used for the simulation. Magnetic\nsurveys are simple to create. The user only needs an (N, 3) array to define\nthe xyz locations of the observation locations, the list of field components\nwhich are to be modeled and the properties of the Earth's field.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the component(s) of the field we are inverting as a list. Here we will\n# invert total magnetic intensity data.\ncomponents = [\"tmi\"]\n\n# Use the observation locations and components to define the receivers. To\n# simulate data, the receivers must be defined as a list.\nreceiver_list = magnetics.receivers.Point(receiver_locations, components=components)\n\nreceiver_list = [receiver_list]\n\n# Define the inducing field H0 = (intensity [nT], inclination [deg], declination [deg])\ninclination = 90\ndeclination = 0\nstrength = 50000\ninducing_field = (strength, inclination, declination)\n\nsource_field = magnetics.sources.SourceField(\n    receiver_list=receiver_list, parameters=inducing_field\n)\n\n# Define the survey\nsurvey = magnetics.survey.Survey(source_field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Data\n\nHere is where we define the data that is inverted. The data is defined by\nthe survey, the observation values and the standard deviations.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_object = data.Data(survey, dobs=dobs, standard_deviation=std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a Tensor Mesh\n\nHere, we create the tensor mesh that will be used to invert TMI data.\nIf desired, we could define an OcTree mesh.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dh = 5.0\nhx = [(dh, 5, -1.3), (dh, 40), (dh, 5, 1.3)]\nhy = [(dh, 5, -1.3), (dh, 40), (dh, 5, 1.3)]\nhz = [(dh, 5, -1.3), (dh, 15)]\nmesh = TensorMesh([hx, hy, hz], \"CCN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Starting/Reference Model and Mapping on Tensor Mesh\n\nHere, we would create starting and/or reference models for the inversion as\nwell as the mapping from the model space to the active cells. Starting and\nreference models can be a constant background value or contain a-priori\nstructures. Here, the background is 1e-4 SI.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define background susceptibility model in SI. Don't make this 0!\n# Otherwise the gradient for the 1st iteration is zero and the inversion will\n# not converge.\nbackground_susceptibility = 1e-4\n\n# Find the indecies of the active cells in forward model (ones below surface)\nactive_cells = surface2ind_topo(mesh, topo_xyz)\n\n# Define mapping from model to active cells\nnC = int(active_cells.sum())\nmodel_map = maps.IdentityMap(nP=nC)  # model consists of a value for each cell\n\n# Define starting model\nstarting_model = background_susceptibility * np.ones(nC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Physics\n\nHere, we define the physics of the magnetics problem by using the simulation\nclass.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the problem. Define the cells below topography and the mapping\nsimulation = magnetics.simulation.Simulation3DIntegral(\n    survey=survey,\n    mesh=mesh,\n    model_type=\"scalar\",\n    chiMap=model_map,\n    ind_active=active_cells,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inverse Problem\n\nThe inverse problem is defined by 3 things:\n\n    1) Data Misfit: a measure of how well our recovered model explains the field data\n    2) Regularization: constraints placed on the recovered model and a priori information\n    3) Optimization: the numerical approach used to solve the inverse problem\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the data misfit. Here the data misfit is the L2 norm of the weighted\n# residual between the observed data and the data predicted for a given model.\n# Within the data misfit, the residual between predicted and observed data are\n# normalized by the data's standard deviation.\ndmis = data_misfit.L2DataMisfit(data=data_object, simulation=simulation)\n\n# Define the regularization (model objective function)\nreg = regularization.Sparse(\n    mesh,\n    active_cells=active_cells,\n    mapping=model_map,\n    reference_model=starting_model,\n    gradient_type=\"total\",\n)\n\n# Define sparse and blocky norms p, qx, qy, qz\nreg.norms = [0, 0, 0, 0]\n\n# Define how the optimization problem is solved. Here we will use a projected\n# Gauss-Newton approach that employs the conjugate gradient solver.\nopt = optimization.ProjectedGNCG(\n    maxIter=20, lower=0.0, upper=1.0, maxIterLS=20, maxIterCG=10, tolCG=1e-3\n)\n\n# Here we define the inverse problem that is to be solved\ninv_prob = inverse_problem.BaseInvProblem(dmis, reg, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inversion Directives\n\nHere we define any directives that are carried out during the inversion. This\nincludes the cooling schedule for the trade-off parameter (beta), stopping\ncriteria for the inversion and saving inversion results at each iteration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Defining a starting value for the trade-off parameter (beta) between the data\n# misfit and the regularization.\nstarting_beta = directives.BetaEstimate_ByEig(beta0_ratio=5)\n\n# Options for outputting recovered models and predicted data for each beta.\nsave_iteration = directives.SaveOutputEveryIteration(save_txt=False)\n\n# Defines the directives for the IRLS regularization. This includes setting\n# the cooling schedule for the trade-off parameter.\nupdate_IRLS = directives.Update_IRLS(\n    f_min_change=1e-4,\n    max_irls_iterations=30,\n    coolEpsFact=1.5,\n    beta_tol=1e-2,\n)\n\n# Updating the preconditioner if it is model dependent.\nupdate_jacobi = directives.UpdatePreconditioner()\n\n# Setting a stopping criteria for the inversion.\ntarget_misfit = directives.TargetMisfit(chifact=1)\n\n# Add sensitivity weights\nsensitivity_weights = directives.UpdateSensitivityWeights(everyIter=False)\n\n# The directives are defined as a list.\ndirectives_list = [\n    sensitivity_weights,\n    starting_beta,\n    save_iteration,\n    update_IRLS,\n    update_jacobi,\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Inversion\n\nTo define the inversion object, we need to define the inversion problem and\nthe set of directives. We can then run the inversion.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here we combine the inverse problem and the set of directives\ninv = inversion.BaseInversion(inv_prob, directives_list)\n\n# Print target misfit to compare with convergence\n# print(\"Target misfit is \" + str(target_misfit.target))\n\n# Run the inversion\nrecovered_model = inv.run(starting_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recreate True Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "background_susceptibility = 0.0001\nsphere_susceptibility = 0.01\n\ntrue_model = background_susceptibility * np.ones(nC)\nind_sphere = model_builder.getIndicesSphere(\n    np.r_[0.0, 0.0, -45.0], 15.0, mesh.cell_centers\n)\nind_sphere = ind_sphere[active_cells]\ntrue_model[ind_sphere] = sphere_susceptibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting True Model and Recovered Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot True Model\nfig = plt.figure(figsize=(9, 4))\nplotting_map = maps.InjectActiveCells(mesh, active_cells, np.nan)\n\nax1 = fig.add_axes([0.08, 0.1, 0.75, 0.8])\nmesh.plot_slice(\n    plotting_map * true_model,\n    normal=\"Y\",\n    ax=ax1,\n    ind=int(mesh.shape_cells[1] / 2),\n    grid=True,\n    clim=(np.min(true_model), np.max(true_model)),\n    pcolor_opts={\"cmap\": \"viridis\"},\n)\nax1.set_title(\"Model slice at y = 0 m\")\n\nax2 = fig.add_axes([0.85, 0.1, 0.05, 0.8])\nnorm = mpl.colors.Normalize(vmin=np.min(true_model), vmax=np.max(true_model))\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.viridis, format=\"%.1e\"\n)\ncbar.set_label(\"SI\", rotation=270, labelpad=15, size=12)\n\nplt.show()\n\n# Plot Recovered Model\nfig = plt.figure(figsize=(9, 4))\nplotting_map = maps.InjectActiveCells(mesh, active_cells, np.nan)\n\nax1 = fig.add_axes([0.08, 0.1, 0.75, 0.8])\nmesh.plot_slice(\n    plotting_map * recovered_model,\n    normal=\"Y\",\n    ax=ax1,\n    ind=int(mesh.shape_cells[1] / 2),\n    grid=True,\n    clim=(np.min(recovered_model), np.max(recovered_model)),\n    pcolor_opts={\"cmap\": \"viridis\"},\n)\nax1.set_title(\"Model slice at y = 0 m\")\n\nax2 = fig.add_axes([0.85, 0.1, 0.05, 0.8])\nnorm = mpl.colors.Normalize(vmin=np.min(recovered_model), vmax=np.max(recovered_model))\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.viridis, format=\"%.1e\"\n)\ncbar.set_label(\"SI\", rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Predicted Data and Misfit\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Predicted data with final recovered model\ndpred = inv_prob.dpred\n\n# Observed data | Predicted data | Normalized data misfit\ndata_array = np.c_[dobs, dpred, (dobs - dpred) / std]\n\nfig = plt.figure(figsize=(17, 4))\nplot_title = [\"Observed\", \"Predicted\", \"Normalized Misfit\"]\nplot_units = [\"nT\", \"nT\", \"\"]\n\nax1 = 3 * [None]\nax2 = 3 * [None]\nnorm = 3 * [None]\ncbar = 3 * [None]\ncplot = 3 * [None]\nv_lim = [np.max(np.abs(dobs)), np.max(np.abs(dobs)), np.max(np.abs(data_array[:, 2]))]\n\nfor ii in range(0, 3):\n\n    ax1[ii] = fig.add_axes([0.33 * ii + 0.03, 0.11, 0.25, 0.84])\n    cplot[ii] = plot2Ddata(\n        receiver_list[0].locations,\n        data_array[:, ii],\n        ax=ax1[ii],\n        ncontour=30,\n        clim=(-v_lim[ii], v_lim[ii]),\n        contourOpts={\"cmap\": \"bwr\"},\n    )\n    ax1[ii].set_title(plot_title[ii])\n    ax1[ii].set_xlabel(\"x (m)\")\n    ax1[ii].set_ylabel(\"y (m)\")\n\n    ax2[ii] = fig.add_axes([0.33 * ii + 0.27, 0.11, 0.01, 0.84])\n    norm[ii] = mpl.colors.Normalize(vmin=-v_lim[ii], vmax=v_lim[ii])\n    cbar[ii] = mpl.colorbar.ColorbarBase(\n        ax2[ii], norm=norm[ii], orientation=\"vertical\", cmap=mpl.cm.bwr\n    )\n    cbar[ii].set_label(plot_units[ii], rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}