{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Cross-gradient Joint Inversion of Gravity and Magnetic Anomaly Data\n\nHere we simultaneously invert gravity and magentic data using cross-gradient\nconstraint. The recovered density and susceptibility models are supposed to have\nstructural similarity. For this tutorial, we focus on the following:\n\n    - Defining the survey from xyz formatted data\n    - Generating a mesh based on survey geometry\n    - Including surface topography\n    - Defining the inverse problem via combmaps (2 data misfit terms,\n        2 regularization terms, a coupling term and optimization)\n    - Specifying directives for the inversion\n    - Plotting the recovered model and data misfit\n\n\nAlthough we consider gravity and magnetic anomaly data in this tutorial,\nthe same approach can be used to invert gradiometry and other types of geophysical data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport tarfile\n\nfrom discretize import TensorMesh\nfrom discretize.utils import active_from_xyz\nfrom SimPEG.utils import plot2Ddata\nfrom SimPEG.potential_fields import gravity, magnetics\nfrom SimPEG import (\n    maps,\n    data,\n    data_misfit,\n    inverse_problem,\n    regularization,\n    optimization,\n    directives,\n    inversion,\n    utils,\n)\n\nnp.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define File Names\n\nFile paths for assets we are loading. To set up the inversion, we require\ntopography and field observations. The true model defined on the whole mesh\nis loaded to compare with the inversion result. These files are stored as a\ntar-file on our google cloud bucket:\n\"https://storage.googleapis.com/simpeg/doc-assets/gravity.tar.gz\"\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# # storage bucket where we have the data\ndata_source = (\n    \"https://storage.googleapis.com/simpeg/doc-assets/cross_gradient_data.tar.gz\"\n)\n\n# # download the data\ndownloaded_data = utils.download(data_source, overwrite=True)\n\n# unzip the tarfile\ntar = tarfile.open(downloaded_data, \"r\")\ntar.extractall()\ntar.close()\n\n# path to the directory containing our data\ndir_path = downloaded_data.split(\".\")[0] + os.path.sep\n\n# files to work with\ntopo_filename = dir_path + \"topo.txt\"\nmodel_filename = dir_path + \"true_model.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Plot\n\nHere we load and plot synthetic gravity anomaly data. Topography is generally\ndefined as an (N, 3) array. Gravity data is generally defined with 4 columns:\nx, y, z and data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load topography\nxyz_topo = np.loadtxt(topo_filename)\n\n# Load field data\ndobs_grav = np.loadtxt(dir_path + \"gravity_data.obs\")\ndobs_mag = np.loadtxt(dir_path + \"magnetic_data.obs\")\n\n# Define receiver locations and observed data\nreceiver_locations = dobs_grav[:, 0:3]\n\ndobs_grav = dobs_grav[:, -1]\ndobs_mag = dobs_mag[:, -1]\n\n# Plot\nmpl.rcParams.update({\"font.size\": 12})\n\n# gravity data\nfig = plt.figure(figsize=(7, 5))\n\nax1 = fig.add_axes([0.1, 0.1, 0.73, 0.85])\nplot2Ddata(receiver_locations, dobs_grav, ax=ax1, contourOpts={\"cmap\": \"bwr\"})\nax1.set_title(\"Gravity Anomaly\")\nax1.set_xlabel(\"x (m)\")\nax1.set_ylabel(\"y (m)\")\n\nax2 = fig.add_axes([0.8, 0.1, 0.03, 0.85])\nnorm = mpl.colors.Normalize(\n    vmin=-np.max(np.abs(dobs_grav)), vmax=np.max(np.abs(dobs_grav))\n)\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.bwr, format=\"%.1e\"\n)\ncbar.set_label(\"$mgal$\", rotation=270, labelpad=15, size=12)\n\n# magnetic data\nfig = plt.figure(figsize=(7, 5))\nax1 = fig.add_axes([0.1, 0.1, 0.73, 0.85])\nplot2Ddata(receiver_locations, dobs_mag, ax=ax1, contourOpts={\"cmap\": \"bwr\"})\nax1.set_title(\"Magnetic Anomaly\")\nax1.set_xlabel(\"x (m)\")\nax1.set_ylabel(\"y (m)\")\n\nax2 = fig.add_axes([0.8, 0.1, 0.03, 0.85])\nnorm = mpl.colors.Normalize(\n    vmin=-np.max(np.abs(dobs_mag)), vmax=np.max(np.abs(dobs_mag))\n)\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.bwr, format=\"%.1e\"\n)\ncbar.set_label(\"$nT$\", rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assign Uncertainties\n\nInversion with SimPEG requires that we define standard deviation on our data.\nThis represents our estimate of the noise in our data. For gravity inversion,\na constant floor value is generally applied to all data. For this tutorial,\nthe standard deviation on each datum will be 1% of the maximum observed\ngravity anomaly value. For magnetic inversion, the same strategy is performed.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximum_anomaly_grav = np.max(np.abs(dobs_grav))\nuncertainties_grav = 0.01 * maximum_anomaly_grav * np.ones(np.shape(dobs_grav))\n\nmaximum_anomaly_mag = np.max(np.abs(dobs_mag))\nuncertainties_mag = 0.01 * maximum_anomaly_mag * np.ones(np.shape(dobs_mag))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Survey\n\nHere, we define survey that will be used for this tutorial. Gravity\nsurveys are simple to create. The user only needs an (N, 3) array to define\nthe xyz locations of the observation locations. From this, the user can\ndefine the receivers and the source field.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the receivers. The data consist of vertical gravity anomaly measurements.\n# The set of receivers must be defined as a list.\nreceiver_grav = gravity.receivers.Point(receiver_locations, components=\"gz\")\n\n# Define the source field and survey for gravity data\nsource_field_grav = gravity.sources.SourceField(receiver_list=[receiver_grav])\nsurvey_grav = gravity.survey.Survey(source_field_grav)\n\n\n# Define the component(s) of the field we want to simulate as a list of strings.\n# Here we simulation total magnetic intensity data.\ncomponents = [\"tmi\"]\n\n# Use the observation locations and components to define the receivers. To\n# simulate data, the receivers must be defined as a list.\nreceiver_mag = magnetics.receivers.Point(receiver_locations, components=components)\n\n# Define the inducing field H0 = (intensity [nT], inclination [deg], declination [deg])\ninclination = 90\ndeclination = 0\nstrength = 50000\n\n# Define the source field and survey for gravity data\nsource_field_mag = magnetics.sources.UniformBackgroundField(\n    receiver_list=[receiver_mag],\n    amplitude=strength,\n    inclination=inclination,\n    declination=declination,\n)\nsurvey_mag = magnetics.survey.Survey(source_field_mag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Data\n\nHere is where we define the data that are inverted. The data are defined by\nthe survey, the observation values and the standard deviation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_object_grav = data.Data(\n    survey_grav, dobs=dobs_grav, standard_deviation=uncertainties_grav\n)\ndata_object_mag = data.Data(\n    survey_mag, dobs=dobs_mag, standard_deviation=uncertainties_mag\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a Tensor Mesh\n\nHere, we create the tensor mesh that will be used to invert gravity anomaly\ndata. If desired, we could define an OcTree mesh.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dh = 5.0\nhx = [(dh, 5, -1.3), (dh, 40), (dh, 5, 1.3)]\nhy = [(dh, 5, -1.3), (dh, 40), (dh, 5, 1.3)]\nhz = [(dh, 5, -1.3), (dh, 15)]\nmesh = TensorMesh([hx, hy, hz], \"CCN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Starting/Reference Model and Mapping on Tensor Mesh\n\nHere, we create starting and/or reference models for the inversion as\nwell as the mapping from the model space to the active cells. Starting and\nreference models can be a constant background value or contain a-priori\nstructures. Here, the backgrounds are 1e-6 g/cc and 1e-6 SI for density and\nsusceptibility models, respectively. Note that the background values could\nbe different for density and susceptibility models.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define density contrast values for each unit in g/cc.\nbackground_dens, background_susc = 1e-6, 1e-6\n\n# Find the indicies of the active cells in forward model (ones below surface)\nind_active = active_from_xyz(mesh, xyz_topo)\n\n# Define mapping from model to active cells\nnC = int(ind_active.sum())\nmodel_map = maps.IdentityMap(nP=nC)  # model consists of a value for each active cell\n\n# Create Wires Map that maps from stacked models to individual model components\n# m1 refers to density model, m2 refers to susceptibility\nwires = maps.Wires((\"density\", nC), (\"susceptibility\", nC))\n\n# Define and plot starting model\nstarting_model = np.r_[background_dens * np.ones(nC), background_susc * np.ones(nC)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Physics\n\nHere, we define the physics of the gravity and magnetic problems by using the simulation\nclass.\n\n.. tip::\n\n   Since SimPEG v0.21.0 we can use [Choclo](https://www.fatiando.org/choclo) as the engine for running the gravity\n   simulations, which results in faster and more memory efficient runs. Just\n   pass ``engine=\"choclo\"`` when constructing the simulation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "simulation_grav = gravity.simulation.Simulation3DIntegral(\n    survey=survey_grav,\n    mesh=mesh,\n    rhoMap=wires.density,\n    ind_active=ind_active,\n    engine=\"choclo\",\n)\n\nsimulation_mag = magnetics.simulation.Simulation3DIntegral(\n    survey=survey_mag,\n    mesh=mesh,\n    model_type=\"scalar\",\n    chiMap=wires.susceptibility,\n    ind_active=ind_active,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Inverse Problem\n\nThe inverse problem is defined by 4 things:\n\n    1) Data Misfit: a measure of how well our recovered model explains the field data\n    2) Regularization: constraints placed on the recovered model and a priori information\n    3) Coupling: a connection of two different physical property models\n    4) Optimization: the numerical approach used to solve the inverse problem\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the data misfit. Here the data misfit is the L2 norm of the weighted\n# residual between the observed data and the data predicted for a given model.\n# Within the data misfit, the residual between predicted and observed data are\n# normalized by the data's standard deviation.\ndmis_grav = data_misfit.L2DataMisfit(data=data_object_grav, simulation=simulation_grav)\ndmis_mag = data_misfit.L2DataMisfit(data=data_object_mag, simulation=simulation_mag)\n\n# Define the regularization (model objective function).\nreg_grav = regularization.WeightedLeastSquares(\n    mesh, active_cells=ind_active, mapping=wires.density\n)\nreg_mag = regularization.WeightedLeastSquares(\n    mesh, active_cells=ind_active, mapping=wires.susceptibility\n)\n\n# Define the coupling term to connect two different physical property models\nlamda = 2e12  # weight for coupling term\ncross_grad = regularization.CrossGradient(mesh, wires, active_cells=ind_active)\n\n# combo\ndmis = dmis_grav + dmis_mag\nreg = reg_grav + reg_mag + lamda * cross_grad\n\n# Define how the optimization problem is solved. Here we will use a projected\n# Gauss-Newton approach that employs the conjugate gradient solver.\nopt = optimization.ProjectedGNCG(\n    maxIter=10,\n    lower=-2.0,\n    upper=2.0,\n    maxIterLS=20,\n    maxIterCG=100,\n    tolCG=1e-3,\n    tolX=1e-3,\n)\n\n# Here we define the inverse problem that is to be solved\ninv_prob = inverse_problem.BaseInvProblem(dmis, reg, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inversion Directives\n\nHere we define any directiveas that are carried out during the inversion. This\nincludes the cooling schedule for the trade-off parameter (beta), stopping\ncriteria for the inversion and saving inversion results at each iteration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Defining a starting value for the trade-off parameter (beta) between the data\n# misfit and the regularization.\nstarting_beta = directives.PairedBetaEstimate_ByEig(beta0_ratio=1e0)\n# starting_beta.n_pw_iter = 10\n\n# Defining the fractional decrease in beta and the number of Gauss-Newton solves\n# for each beta value.\nbeta_schedule = directives.PairedBetaSchedule(cooling_factor=5, cooling_rate=1)\n\n# Options for outputting recovered models and predicted data for each beta.\nsave_iteration = directives.SimilarityMeasureSaveOutputEveryIteration(save_txt=False)\n\njoint_inv_dir = directives.SimilarityMeasureInversionDirective()\n\nstopping = directives.MovingAndMultiTargetStopping(tol=1e-6)\n\nsensitivity_weights = directives.UpdateSensitivityWeights(every_iteration=False)\n\n# Updating the preconditionner if it is model dependent.\nupdate_jacobi = directives.UpdatePreconditioner()\n\n\n# The directives are defined as a list.\ndirectives_list = [\n    joint_inv_dir,\n    sensitivity_weights,\n    stopping,\n    starting_beta,\n    beta_schedule,\n    save_iteration,\n    update_jacobi,\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Inversion\n\nTo define the inversion object, we need to define the inversion problem and\nthe set of directives. We can then run the inversion.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here we combine the inverse problem and the set of directives\ninv = inversion.BaseInversion(inv_prob, directives_list)\n\n# Run inversion\nrecovered_model = inv.run(starting_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting True Model and Recovered Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the true model (was defined on the whole mesh) and extract only the\n# values on active cells.\n\ntrue_model_dens = np.loadtxt(dir_path + \"true_model_dens.txt\")\ntrue_model_dens[~ind_active] = np.NaN\n\ntrue_model_susc = np.loadtxt(dir_path + \"true_model_susc.txt\")\ntrue_model_susc[~ind_active] = np.NaN\n\n# Plot True Model\nfig = plt.figure(figsize=(9, 8))\nax1 = plt.subplot(211)\n\n(im,) = mesh.plot_slice(true_model_dens, normal=\"Y\", ax=ax1, grid=True)\nax1.set_title(\"True density model slice at y = 0 m\")\ncbar = plt.colorbar(im, format=\"%.1e\")\ncbar.set_label(\"g/cc\", rotation=270, labelpad=15, size=12)\n\nax2 = plt.subplot(212)\n(im,) = mesh.plot_slice(\n    true_model_susc, normal=\"Y\", ax=ax2, grid=True, pcolor_opts={\"cmap\": \"inferno\"}\n)\n\nax2.set_title(\"True susceptibility model slice at y = 0 m\")\ncbar = plt.colorbar(im, format=\"%.1e\")\ncbar.set_label(\"SI\", rotation=270, labelpad=15, size=12)\nplt.tight_layout()\nplt.show()\n\n# Plot Recovered Model\nm_dens_joint, m_susc_joint = wires * recovered_model\nplotting_map = maps.InjectActiveCells(mesh, ind_active, np.nan)\n\nfig = plt.figure(figsize=(9, 8))\nax1 = plt.subplot(211)\n(im,) = mesh.plot_slice(\n    plotting_map * m_dens_joint,\n    normal=\"Y\",\n    ax=ax1,\n    clim=(-0.04, 0.03),\n)\nax1.set_title(\"Density model slice at y = 0 m\")\ncbar = plt.colorbar(im)\ncbar.set_label(\"g/cc\", rotation=270, labelpad=15, size=12)\n\nax2 = plt.subplot(212)\n(im,) = mesh.plot_slice(\n    plotting_map * m_susc_joint, normal=\"Y\", ax=ax2, pcolor_opts={\"cmap\": \"inferno\"}\n)\nax2.set_title(\"Susceptibility model slice at y = 0 m\")\ncbar = plt.colorbar(im)\ncbar.set_label(\"SI\", rotation=270, labelpad=15, size=12)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing jointly and separatly recovered models\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Normalized Cross Gradient of Jointly Recovered Susceptibility and Density Models\nncg = cross_grad.calculate_cross_gradient(recovered_model, normalized=True)\n\nfig = plt.figure(figsize=(9, 4))\nax = plt.subplot(111)\n(im,) = mesh.plot_slice(\n    plotting_map * ncg,\n    normal=\"Y\",\n    ax=ax,\n    grid=True,\n)\nax.set_title(\"Normalized cross gradient for joint inversion slice at y = 0 m\")\ncbar = plt.colorbar(im, format=\"%.1e\")\ncbar.set_label(\"|cross grad|\", rotation=270, labelpad=15, size=12)\nplt.show()\n\n# Normalized Cross Gradient of Separately Recovered Susceptibility and Density Models\nm_dens_single = np.loadtxt(dir_path + \"single_model_dens.txt\")\nm_susc_single = np.loadtxt(dir_path + \"single_model_susc.txt\")\nm_separate = np.r_[m_dens_single[ind_active], m_susc_single[ind_active]]\n\nncg_single = cross_grad.calculate_cross_gradient(m_separate, normalized=True)\n\nfig = plt.figure(figsize=(9, 4))\nax = plt.subplot(111)\n(im,) = mesh.plot_slice(\n    plotting_map * ncg_single,\n    normal=\"Y\",\n    ax=ax,\n    grid=True,\n)\nax.set_title(\"Normalized cross gradient for separate inversion slice at y = 0 m\")\ncbar = plt.colorbar(im, format=\"%.1e\")\ncbar.set_label(\"|cross grad|\", rotation=270, labelpad=15, size=12)\n\nplt.show()\n\n\n# Cross Plots Recovered Susceptibility and Density Models\nfig = plt.figure(figsize=(14, 5))\nax0 = plt.subplot(121)\nax0.scatter(\n    plotting_map * m_dens_joint, plotting_map * m_susc_joint, s=4, c=\"black\", alpha=0.1\n)\n\nax0.set_xlabel(\"Density\", size=12)\nax0.set_ylabel(\"Susceptibility\", size=12)\nax0.tick_params(labelsize=12)\nax0.set_title(\"Joint inversion\")\n\nax1 = plt.subplot(122)\nax1.scatter(m_dens_single, m_susc_single, s=4, c=\"black\", alpha=0.1)\n\nax1.set_xlabel(\"Density\", size=12)\nax1.set_ylabel(\"Susceptibility\", size=12)\nax1.tick_params(labelsize=12)\nax1.set_title(\"Separate inversion\")\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}