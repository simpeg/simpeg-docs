{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Least-Squares Inversion of Gravity Anomaly Data\n\nHere we invert gravity anomaly data to recover a density contrast model. We\nformulate the inverse problem as a least-squares optimization problem. For\nthis tutorial, we focus on the following:\n\n    - Defining the survey from xyz formatted data\n    - Generating a mesh based on survey geometry\n    - Including surface topography\n    - Defining the inverse problem (data misfit, regularization, optimization)\n    - Specifying directives for the inversion\n    - Plotting the recovered model and data misfit\n\nAlthough we consider gravity anomaly data in this tutorial, the same approach\ncan be used to invert gradiometry and other types of geophysical data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport tarfile\n\nfrom discretize import TensorMesh\nfrom discretize.utils import active_from_xyz\nfrom SimPEG.utils import plot2Ddata, model_builder\nfrom SimPEG.potential_fields import gravity\nfrom SimPEG import (\n    maps,\n    data,\n    data_misfit,\n    inverse_problem,\n    regularization,\n    optimization,\n    directives,\n    inversion,\n    utils,\n)\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define File Names\n\nFile paths for assets we are loading. To set up the inversion, we require\ntopography and field observations. The true model defined on the whole mesh\nis loaded to compare with the inversion result. These files are stored as a\ntar-file on our google cloud bucket:\n\"https://storage.googleapis.com/simpeg/doc-assets/gravity.tar.gz\"\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# storage bucket where we have the data\ndata_source = \"https://storage.googleapis.com/simpeg/doc-assets/gravity.tar.gz\"\n\n# download the data\ndownloaded_data = utils.download(data_source, overwrite=True)\n\n# unzip the tarfile\ntar = tarfile.open(downloaded_data, \"r\")\ntar.extractall()\ntar.close()\n\n# path to the directory containing our data\ndir_path = downloaded_data.split(\".\")[0] + os.path.sep\n\n# files to work with\ntopo_filename = dir_path + \"gravity_topo.txt\"\ndata_filename = dir_path + \"gravity_data.obs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Plot\n\nHere we load and plot synthetic gravity anomaly data. Topography is generally\ndefined as an (N, 3) array. Gravity data is generally defined with 4 columns:\nx, y, z and data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load topography\nxyz_topo = np.loadtxt(str(topo_filename))\n\n# Load field data\ndobs = np.loadtxt(str(data_filename))\n\n# Define receiver locations and observed data\nreceiver_locations = dobs[:, 0:3]\ndobs = dobs[:, -1]\n\n# Plot\nmpl.rcParams.update({\"font.size\": 12})\nfig = plt.figure(figsize=(7, 5))\n\nax1 = fig.add_axes([0.1, 0.1, 0.73, 0.85])\nplot2Ddata(receiver_locations, dobs, ax=ax1, contourOpts={\"cmap\": \"bwr\"})\nax1.set_title(\"Gravity Anomaly\")\nax1.set_xlabel(\"x (m)\")\nax1.set_ylabel(\"y (m)\")\n\nax2 = fig.add_axes([0.8, 0.1, 0.03, 0.85])\nnorm = mpl.colors.Normalize(vmin=-np.max(np.abs(dobs)), vmax=np.max(np.abs(dobs)))\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.bwr, format=\"%.1e\"\n)\ncbar.set_label(\"$mgal$\", rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assign Uncertainties\n\nInversion with SimPEG requires that we define the standard deviation of our data.\nThis represents our estimate of the noise in our data. For a gravity inversion,\na constant floor value is generally applied to all data. For this tutorial,\nthe standard deviation on each datum will be 1% of the maximum observed\ngravity anomaly value.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximum_anomaly = np.max(np.abs(dobs))\n\nuncertainties = 0.01 * maximum_anomaly * np.ones(np.shape(dobs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Survey\n\nHere, we define the survey that will be used for this tutorial. Gravity\nsurveys are simple to create. The user only needs an (N, 3) array to define\nthe xyz locations of the observation locations. From this, the user can\ndefine the receivers and the source field.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the receivers. The data consists of vertical gravity anomaly measurements.\n# The set of receivers must be defined as a list.\nreceiver_list = gravity.receivers.Point(receiver_locations, components=\"gz\")\n\nreceiver_list = [receiver_list]\n\n# Define the source field\nsource_field = gravity.sources.SourceField(receiver_list=receiver_list)\n\n# Define the survey\nsurvey = gravity.survey.Survey(source_field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Data\n\nHere is where we define the data that is inverted. The data is defined by\nthe survey, the observation values and the standard deviation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_object = data.Data(survey, dobs=dobs, standard_deviation=uncertainties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a Tensor Mesh\n\nHere, we create the tensor mesh that will be used to invert gravity anomaly\ndata. If desired, we could define an OcTree mesh.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dh = 5.0\nhx = [(dh, 5, -1.3), (dh, 40), (dh, 5, 1.3)]\nhy = [(dh, 5, -1.3), (dh, 40), (dh, 5, 1.3)]\nhz = [(dh, 5, -1.3), (dh, 15)]\nmesh = TensorMesh([hx, hy, hz], \"CCN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Starting/Reference Model and Mapping on Tensor Mesh\n\nHere, we create starting and/or reference models for the inversion as\nwell as the mapping from the model space to the active cells. Starting and\nreference models can be a constant background value or contain a-priori\nstructures.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Find the indices of the active cells in forward model (ones below surface)\nind_active = active_from_xyz(mesh, xyz_topo)\n\n# Define mapping from model to active cells\nnC = int(ind_active.sum())\nmodel_map = maps.IdentityMap(nP=nC)  # model consists of a value for each active cell\n\n# Define and plot starting model\nstarting_model = np.zeros(nC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Physics\n\nHere, we define the physics of the gravity problem by using the simulation\nclass.\n\n.. tip::\n\n   Since SimPEG v0.21.0 we can use [Choclo](https://www.fatiando.org/choclo) as the engine for running the gravity\n   simulations, which results in faster and more memory efficient runs. Just\n   pass ``engine=\"choclo\"`` when constructing the simulation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "simulation = gravity.simulation.Simulation3DIntegral(\n    survey=survey,\n    mesh=mesh,\n    rhoMap=model_map,\n    ind_active=ind_active,\n    engine=\"choclo\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Inverse Problem\n\nThe inverse problem is defined by 3 things:\n\n    1) Data Misfit: a measure of how well our recovered model explains the field data\n    2) Regularization: constraints placed on the recovered model and a priori information\n    3) Optimization: the numerical approach used to solve the inverse problem\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the data misfit. Here the data misfit is the L2 norm of the weighted\n# residual between the observed data and the data predicted for a given model.\n# Within the data misfit, the residual between predicted and observed data are\n# normalized by the data's standard deviation.\ndmis = data_misfit.L2DataMisfit(data=data_object, simulation=simulation)\n\n# Define the regularization (model objective function).\nreg = regularization.WeightedLeastSquares(\n    mesh, active_cells=ind_active, mapping=model_map\n)\n\n# Define how the optimization problem is solved. Here we will use a projected\n# Gauss-Newton approach that employs the conjugate gradient solver.\nopt = optimization.ProjectedGNCG(\n    maxIter=10, lower=-1.0, upper=1.0, maxIterLS=20, maxIterCG=10, tolCG=1e-3\n)\n\n# Here we define the inverse problem that is to be solved\ninv_prob = inverse_problem.BaseInvProblem(dmis, reg, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inversion Directives\n\nHere we define any directiveas that are carried out during the inversion. This\nincludes the cooling schedule for the trade-off parameter (beta), stopping\ncriteria for the inversion and saving inversion results at each iteration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Defining a starting value for the trade-off parameter (beta) between the data\n# misfit and the regularization.\nstarting_beta = directives.BetaEstimate_ByEig(beta0_ratio=1e1)\n\n# Defining the fractional decrease in beta and the number of Gauss-Newton solves\n# for each beta value.\nbeta_schedule = directives.BetaSchedule(coolingFactor=5, coolingRate=1)\n\n# Options for outputting recovered models and predicted data for each beta.\nsave_iteration = directives.SaveOutputEveryIteration(save_txt=False)\n\n# Updating the preconditionner if it is model dependent.\nupdate_jacobi = directives.UpdatePreconditioner()\n\n# Setting a stopping criteria for the inversion.\ntarget_misfit = directives.TargetMisfit(chifact=1)\n\n# Add sensitivity weights\nsensitivity_weights = directives.UpdateSensitivityWeights(every_iteration=False)\n\n# The directives are defined as a list.\ndirectives_list = [\n    sensitivity_weights,\n    starting_beta,\n    beta_schedule,\n    save_iteration,\n    update_jacobi,\n    target_misfit,\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Inversion\n\nTo define the inversion object, we need to define the inversion problem and\nthe set of directives. We can then run the inversion.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here we combine the inverse problem and the set of directives\ninv = inversion.BaseInversion(inv_prob, directives_list)\n\n# Run inversion\nrecovered_model = inv.run(starting_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recreate True Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define density contrast values for each unit in g/cc\nbackground_density = 0.0\nblock_density = -0.2\nsphere_density = 0.2\n\n# Define model. Models in SimPEG are vector arrays.\ntrue_model = background_density * np.ones(nC)\n\n# You could find the indicies of specific cells within the model and change their\n# value to add structures.\nind_block = (\n    (mesh.gridCC[ind_active, 0] > -50.0)\n    & (mesh.gridCC[ind_active, 0] < -20.0)\n    & (mesh.gridCC[ind_active, 1] > -15.0)\n    & (mesh.gridCC[ind_active, 1] < 15.0)\n    & (mesh.gridCC[ind_active, 2] > -50.0)\n    & (mesh.gridCC[ind_active, 2] < -30.0)\n)\ntrue_model[ind_block] = block_density\n\n# You can also use SimPEG utilities to add structures to the model more concisely\nind_sphere = model_builder.get_indices_sphere(\n    np.r_[35.0, 0.0, -40.0], 15.0, mesh.gridCC\n)\nind_sphere = ind_sphere[ind_active]\ntrue_model[ind_sphere] = sphere_density"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting True Model and Recovered Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot True Model\nfig = plt.figure(figsize=(9, 4))\nplotting_map = maps.InjectActiveCells(mesh, ind_active, np.nan)\n\nax1 = fig.add_axes([0.1, 0.1, 0.73, 0.8])\nmesh.plot_slice(\n    plotting_map * true_model,\n    normal=\"Y\",\n    ax=ax1,\n    ind=int(mesh.shape_cells[1] / 2),\n    grid=True,\n    clim=(np.min(true_model), np.max(true_model)),\n    pcolor_opts={\"cmap\": \"viridis\"},\n)\nax1.set_title(\"Model slice at y = 0 m\")\n\n\nax2 = fig.add_axes([0.85, 0.1, 0.05, 0.8])\nnorm = mpl.colors.Normalize(vmin=np.min(true_model), vmax=np.max(true_model))\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.viridis, format=\"%.1e\"\n)\ncbar.set_label(\"$g/cm^3$\", rotation=270, labelpad=15, size=12)\n\nplt.show()\n\n# Plot Recovered Model\nfig = plt.figure(figsize=(9, 4))\nplotting_map = maps.InjectActiveCells(mesh, ind_active, np.nan)\n\nax1 = fig.add_axes([0.1, 0.1, 0.73, 0.8])\nmesh.plot_slice(\n    plotting_map * recovered_model,\n    normal=\"Y\",\n    ax=ax1,\n    ind=int(mesh.shape_cells[1] / 2),\n    grid=True,\n    clim=(np.min(recovered_model), np.max(recovered_model)),\n    pcolor_opts={\"cmap\": \"viridis\"},\n)\nax1.set_title(\"Model slice at y = 0 m\")\n\nax2 = fig.add_axes([0.85, 0.1, 0.05, 0.8])\nnorm = mpl.colors.Normalize(vmin=np.min(recovered_model), vmax=np.max(recovered_model))\ncbar = mpl.colorbar.ColorbarBase(\n    ax2, norm=norm, orientation=\"vertical\", cmap=mpl.cm.viridis\n)\ncbar.set_label(\"$g/cm^3$\", rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Predicted Data and Normalized Misfit\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Predicted data with final recovered model\n# SimPEG uses right handed coordinate where Z is positive upward.\n# This causes gravity signals look \"inconsistent\" with density values in visualization.\ndpred = inv_prob.dpred\n\n# Observed data | Predicted data | Normalized data misfit\ndata_array = np.c_[dobs, dpred, (dobs - dpred) / uncertainties]\n\nfig = plt.figure(figsize=(17, 4))\nplot_title = [\"Observed\", \"Predicted\", \"Normalized Misfit\"]\nplot_units = [\"mgal\", \"mgal\", \"\"]\n\nax1 = 3 * [None]\nax2 = 3 * [None]\nnorm = 3 * [None]\ncbar = 3 * [None]\ncplot = 3 * [None]\nv_lim = [np.max(np.abs(dobs)), np.max(np.abs(dobs)), np.max(np.abs(data_array[:, 2]))]\n\nfor ii in range(0, 3):\n    ax1[ii] = fig.add_axes([0.33 * ii + 0.03, 0.11, 0.23, 0.84])\n    cplot[ii] = plot2Ddata(\n        receiver_list[0].locations,\n        data_array[:, ii],\n        ax=ax1[ii],\n        ncontour=30,\n        clim=(-v_lim[ii], v_lim[ii]),\n        contourOpts={\"cmap\": \"bwr\"},\n    )\n    ax1[ii].set_title(plot_title[ii])\n    ax1[ii].set_xlabel(\"x (m)\")\n    ax1[ii].set_ylabel(\"y (m)\")\n\n    ax2[ii] = fig.add_axes([0.33 * ii + 0.25, 0.11, 0.01, 0.85])\n    norm[ii] = mpl.colors.Normalize(vmin=-v_lim[ii], vmax=v_lim[ii])\n    cbar[ii] = mpl.colorbar.ColorbarBase(\n        ax2[ii], norm=norm[ii], orientation=\"vertical\", cmap=mpl.cm.bwr\n    )\n    cbar[ii].set_label(plot_units[ii], rotation=270, labelpad=15, size=12)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}